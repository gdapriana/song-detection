{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T16:38:03.621758Z",
     "start_time": "2025-01-29T16:38:02.859395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "bea364962e32f1fe",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PRE-EMPHASIS",
   "id": "ab1ac58885cc7d39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Pre-emphasis is an initial stage in the Mel Frequency Cepstral Coefficients (MFCC) extraction process to improve the quality of the sound signal before extracting its features. Pre-emphasis is done by applying a high-pass filter to amplify the high frequency components of the audio signal.\n",
    "\n",
    "$$y(n)=x(n)-\\alpha.x(n-1)$$\n",
    "\n",
    "- $n$ is the input signal.\n",
    "- $y(n)$ is the signal after pre-emphasis.\n",
    "- $\\alpha$ is the *pre-emphasis* coefficient which is in the range of 0 to 1. The commonly used value of *Î±* is about 0.95."
   ],
   "id": "4706f3a23be2977b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T16:35:41.772093Z",
     "start_time": "2025-01-29T16:35:41.768688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pre_emphasis__(signal, coefficient=0.97):\n",
    "  return np.append(signal[0], signal[1:] - coefficient * signal[:-1])"
   ],
   "id": "76747158676993e5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FRAME BLOCKING",
   "id": "eb5ee264b259434e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the Frame Blocking process, the speech signal is split into many small chunks called frames, with each frame overlapping each other. This process is designed to minimize the loss of important information (deleted) or disconnected pieces of signal during frame division. This operation continues until the entire audio signal is thoroughly mapped into frames. By dividing the signal into frames, the information contained in it can be represented in a more detailed and specific manner, making it easier for sound processing algorithms to process. In addition, frame blocking also plays an important role in overcoming variations in the duration of the sound signal, making the feature extraction process more consistent and reliable for various purposes, such as speech recognition or audio analysis.\n",
    "\n",
    "$$frame = \\frac {I-N} {M} + 1$$\n",
    "\n",
    "Description:\n",
    "- $I$ is the value of *sampling rates.*\n",
    "- $N$ indicates the *size* of *frame blocking.*\n",
    "- $M$ is the length of *overlap.*"
   ],
   "id": "582a4c86b90d4577"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def framing__(signal, sr, frame_size=1, frame_stride=0.5):\n",
    "  frame_length, frame_step = int(round(frame_size * sr)), int(round(frame_stride * sr))\n",
    "  signal_length = len(signal)\n",
    "  num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step) + 1)\n",
    "  \n",
    "  pad_signal_length = (num_frames - 1) * frame_step + frame_length\n",
    "  z = np.zeros((pad_signal_length - signal_length))\n",
    "  pad_signal = np.append(signal, z)\n",
    "  indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "  framed_signal = pad_signal[indices.astype(np.int32, copy=False)]\n",
    "  return framed_signal"
   ],
   "id": "543706d2410c8c1f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
